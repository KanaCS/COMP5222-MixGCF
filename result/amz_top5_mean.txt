Script started on Mon 15 Nov 2021 02:37:38 AM HKT
kttchungac@dycpu3:MixGCF\[ttchungac@dycpu3 MixGCF]$ c[Kbash
(base) [01;32mttchungac@dycpu3[00m:[01;34m~/mixgcf/topkmean/MixGCF$[00m conda activate pt170
(pt170) [01;32mttchungac@dycpu3[00m:[01;34m~/mixgcf/topkmean/MixGCF$[00m python main.py --dataset amazon --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 3 --gnn lightgcn  --topk 5 --context_hops 3 --pool mean --ns mixgcf --K 1 --n_negs 16M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C --gnn lightgcn --[1PM(pt170) [01;32mttchungac@dycpu3[00m:[01;34m~/mixgcf/topkmean/MixGCF$[00m [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C0 --gnn lightgcn -[1@-M(pt170) [01;32mttchungac@dycpu3[00m:[01;34m~/mixgcf/topkmean/MixGCF$[00m [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C

reading train and test user-item set ...
building the adj mat ...
loading over ...
start training ...
Traceback (most recent call last):
  File "main.py", line 111, in <module>
    batch_loss.backward()
  File "/home/dycpu1/ttchungac/miniconda3/envs/pt170/lib/python3.7/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/dycpu1/ttchungac/miniconda3/envs/pt170/lib/python3.7/site-packages/torch/autograd/__init__.py", line 132, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 188.00 MiB (GPU 0; 23.70 GiB total capacity; 823.85 MiB already allocated; 186.56 MiB free; 898.00 MiB reserved in total by PyTorch)
(pt170) [01;32mttchungac@dycpu3[00m:[01;34m~/mixgcf/topkmean/MixGCF$[00m python main.py --dataset amazon --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 0 --gnn lightgcn ---topk 5 --context_hops 3 --pool mean --ns mixgcf --K 1 --n_negs 16M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C --gnn lightgcn --[1PM(pt170) [01;32mttchungac@dycpu3[00m:[01;34m~/mixgcf/topkmean/MixGCF$[00m [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C4 --gnn lightgcn -[1@-M(pt170) [01;32mttchungac@dycpu3[00m:[01;34m~/mixgcf/topkmean/MixGCF$[00m [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C

reading train and test user-item set ...
building the adj mat ...
loading over ...
start training ...
) +-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 137.58021664619446 | 624.8060510158539 | 411.4840393066406 | [0.01482882 0.0375864  0.04682263] | [0.00569227 0.0105224  0.01219106] | [0.00080908 0.00106758 0.00089209] | [0.01612326 0.04240388 0.05297017] |
|   0   | 137.58021664619446 | 452.3074655532837 | 411.4840393066406 | [0.03523465 0.04580115 0.05980934] | [0.01620809 0.01840817 0.02095292] | [0.00203147 0.00131965 0.00114711] | [0.04041661 0.05228949 0.0679204 ] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 135.2790s, training loss at epoch 1: 368.6111
using time 133.1100s, training loss at epoch 2: 349.7539
using time 130.1499s, training loss at epoch 3: 336.1057
using time 130.2550s, training loss at epoch 4: 324.8573
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 128.97120666503906 | 613.3096921443939  | 314.77874755859375 | [0.02932826 0.05093264 0.06344739] | [0.0118162  0.01636811 0.01865426] | [0.00168754 0.00146738 0.00122348] | [0.03337106 0.05781153 0.07210924] |
|   5   | 128.97120666503906 | 374.99644231796265 | 314.77874755859375 | [0.03850379 0.05364249 0.06809927] | [0.01662267 0.01981432 0.0224759 ] | [0.00225325 0.00158141 0.00134748] | [0.0444504  0.06196426 0.0786824 ] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 127.7132s, training loss at epoch 6: 305.2026
using time 133.2822s, training loss at epoch 7: 295.8216
using time 140.3942s, training loss at epoch 8: 286.0250
using time 142.4845s, training loss at epoch 9: 276.1552
+-------+--------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |       Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 125.70241141319275 | 539.8842787742615  | 265.958740234375 | [0.03364804 0.05467934 0.06902551] | [0.01435436 0.01876568 0.02138288] | [0.00192778 0.00156833 0.00132231] | [0.03811019 0.06173281 0.07784877] |
|   10  | 125.70241141319275 | 391.56717824935913 | 265.958740234375 | [0.0419181  0.06029873 0.07570449] | [0.01773053 0.02159503 0.02442309] | [0.002451   0.00177089 0.00148969] | [0.04831085 0.06932277 0.08696269] |
+-------+--------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 138.3797s, training loss at epoch 11: 255.6087
using time 133.7282s, training loss at epoch 12: 244.6777
using time 139.8161s, training loss at epoch 13: 233.5651
using time 136.3002s, training loss at epoch 14: 222.2032
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 118.80762386322021 | 439.8812484741211 | 210.9534149169922 | [0.03695606 0.05652953 0.07173346] | [0.01616629 0.0202793  0.02305545] | [0.00210486 0.00161726 0.00137269] | [0.04157874 0.06363869 0.08068203] |
|   15  | 118.80762386322021 | 504.4922811985016 | 210.9534149169922 | [0.0452261  0.06711219 0.08348558] | [0.01936011 0.02397207 0.02697407] | [0.00262275 0.00195465 0.00162901] | [0.0516986  0.07657097 0.09521146] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 132.4289s, training loss at epoch 16: 199.7536
using time 142.5460s, training loss at epoch 17: 188.3828
using time 133.6655s, training loss at epoch 18: 177.2807
using time 119.9555s, training loss at epoch 19: 166.2711
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 108.68607234954834 | 451.9961793422699 | 155.62335205078125 | [0.03879256 0.05869341 0.0739028 ] | [0.01726583 0.02145673 0.02423086] | [0.00219869 0.00167604 0.00141054] | [0.0434627  0.06592428 0.08282157] |
|   20  | 108.68607234954834 | 536.3905129432678 | 155.62335205078125 | [0.04750246 0.07111908 0.08820221] | [0.02058293 0.02556323 0.02868956] | [0.00274447 0.00206653 0.00171528] | [0.05403851 0.08094353 0.10025369] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 138.7586s, training loss at epoch 21: 145.5044
using time 120.4278s, training loss at epoch 22: 135.4187
using time 122.2045s, training loss at epoch 23: 125.8936
using time 106.9313s, training loss at epoch 24: 116.7687
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 107.55862832069397 | 532.9569945335388 | 108.60847473144531 | [0.0402642  0.06006706 0.07548677] | [0.01798859 0.02214662 0.02495679] | [0.00228084 0.00171145 0.00143841] | [0.04508379 0.06727518 0.08450838] |
|   25  | 107.55862832069397 | 531.5574958324432 | 108.60847473144531 | [0.04930098 0.0735313  0.09138433] | [0.02145894 0.02656631 0.02983801] | [0.00284019 0.00213152 0.00177555] | [0.05592147 0.08351979 0.1037281 ] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 136.4952s, training loss at epoch 26: 100.5909
using time 132.2006s, training loss at epoch 27: 93.3974
using time 107.9503s, training loss at epoch 28: 86.4089
using time 109.4530s, training loss at epoch 29: 80.1173
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |       Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 111.05154585838318 | 607.6262605190277 | 74.3635025024414 | [0.04064659 0.06056796 0.07597962] | [0.01825151 0.02244243 0.02524712] | [0.00229508 0.00172387 0.00144377] | [0.04536128 0.06774983 0.0849027 ] |
|   30  | 111.05154585838318 | 468.2123153209686 | 74.3635025024414 | [0.0504831  0.07544817 0.0932273 ] | [0.02209903 0.02736311 0.03062012] | [0.00290165 0.00218667 0.0018089 ] | [0.05715839 0.08555244 0.10562681] |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 123.8891s, training loss at epoch 31: 69.0254
using time 107.6829s, training loss at epoch 32: 64.0499
using time 108.6342s, training loss at epoch 33: 59.5277
using time 113.3390s, training loss at epoch 34: 55.3987
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   35  | 123.33247113227844 | 597.5976643562317  | 51.74193572998047 | [0.04064039 0.0607477  0.07603608] | [0.01841671 0.02264521 0.02542729] | [0.00229216 0.00172642 0.00144304] | [0.04532477 0.06785206 0.08485888] |
|   35  | 123.33247113227844 | 443.72259402275085 | 51.74193572998047 | [0.05138993 0.07628    0.09444091] | [0.02248207 0.0277403  0.03107269] | [0.00295049 0.00220834 0.00183464] | [0.05815108 0.08644271 0.10703706] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 108.9557s, training loss at epoch 36: 48.2637
using time 109.0233s, training loss at epoch 37: 45.2703
using time 110.6021s, training loss at epoch 38: 42.3628
using time 131.1158s, training loss at epoch 39: 39.8570
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   40  | 133.43569111824036 | 557.6349654197693 | 37.582759857177734 | [0.04056773 0.06090933 0.075918  ] | [0.01841146 0.02268678 0.0254202 ] | [0.00228559 0.00172953 0.00144109] | [0.04522984 0.06797619 0.08471284] |
|   40  | 133.43569111824036 | 394.7450141906738 | 37.582759857177734 | [0.05211866 0.07693912 0.09483643] | [0.0228904  0.02812661 0.03140959] | [0.00299185 0.00222587 0.00183949] | [0.05890741 0.08712814 0.10736008] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 109.4092s, training loss at epoch 41: 35.4790
using time 111.2864s, training loss at epoch 42: 33.6070
using time 114.7706s, training loss at epoch 43: 31.9290
using time 116.4943s, training loss at epoch 44: 30.4052
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   45  | 134.34006714820862 | 546.7398307323456 | 28.848556518554688 | [0.04047188 0.0605936  0.07568833] | [0.01833763 0.02257074 0.02532184] | [0.00227683 0.00171876 0.00143573] | [0.04505458 0.06760378 0.08443536] |
|   45  | 134.34006714820862 | 396.7345631122589 | 28.848556518554688 | [0.05237407 0.07734817 0.09519081] | [0.02302039 0.02829324 0.03156562] | [0.00300052 0.00223414 0.00184475] | [0.05910437 0.08748267 0.10774612] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 111.5273s, training loss at epoch 46: 27.6088
using time 120.9228s, training loss at epoch 47: 26.5458
using time 128.7074s, training loss at epoch 48: 25.4737
using time 129.5013s, training loss at epoch 49: 24.4234
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   50  | 127.65236401557922 | 506.97328424453735 | 23.58180046081543 | [0.04062851 0.06053225 0.07576273] | [0.01838222 0.02256987 0.025346  ] | [0.00227938 0.00171492 0.00143573] | [0.0451057  0.06745774 0.08447187] |
|   50  | 127.65236401557922 | 357.37026500701904 | 23.58180046081543 | [0.05240017 0.07758229 0.09558862] | [0.02312755 0.02844654 0.03174611] | [0.00300328 0.00224103 0.00185092] | [0.05918316 0.08769539 0.10814005] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 117.3541s, training loss at epoch 51: 22.7133
using time 127.6518s, training loss at epoch 52: 21.9441
using time 124.2638s, training loss at epoch 53: 21.2942
using time 134.7260s, training loss at epoch 54: 20.7748
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   55  | 134.32398414611816 | 456.3924300670624  | 20.145936965942383 | [0.04068362 0.06069502 0.07561714] | [0.01840744 0.02261446 0.0253379 ] | [0.00228121 0.0017173  0.00143354] | [0.04517142 0.06753076 0.08436234] |
|   55  | 134.32398414611816 | 377.69939136505127 | 20.145936965942383 | [0.05240096 0.07742275 0.09598494] | [0.02317959 0.02847445 0.03186841] | [0.00300564 0.00223847 0.00185761] | [0.05919892 0.08755357 0.10853397] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 112.9353s, training loss at epoch 56: 19.6711
using time 114.3511s, training loss at epoch 57: 19.2076
using time 124.3991s, training loss at epoch 58: 18.7422
using time 123.8977s, training loss at epoch 59: 18.3184
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   60  | 135.6544349193573 | 420.6839144229889  | 17.972246170043945 | [0.04049537 0.06065466 0.07546893] | [0.0183918  0.02263231 0.02533767] | [0.00226952 0.00171529 0.00143062] | [0.04492314 0.06749425 0.08416518] |
|   60  | 135.6544349193573 | 392.50426483154297 | 17.972246170043945 | [0.0528323  0.07774839 0.09581927] | [0.02333892 0.02859835 0.03190721] | [0.00303085 0.00224675 0.00185473] | [0.0597189  0.08785296 0.10833701] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 129.0999s, training loss at epoch 61: 17.6299
using time 129.3956s, training loss at epoch 62: 17.3027
using time 130.1855s, training loss at epoch 63: 17.0495
using time 126.8201s, training loss at epoch 64: 16.7620
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   65  | 137.41059732437134 | 405.64050817489624 | 16.509681701660156 | [0.04054652 0.06070777 0.07539018] | [0.01835307 0.02259018 0.02527063] | [0.00227171 0.00171565 0.00142855] | [0.04495966 0.06750885 0.08407025] |
|   65  | 137.41059732437134 | 394.4788246154785  | 16.509681701660156 | [0.05318644 0.07793063 0.09657784] | [0.02350361 0.02873441 0.03213555] | [0.00304818 0.00225462 0.00186694] | [0.06005767 0.08818385 0.10904607] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 128.1236s, training loss at epoch 66: 16.3073
using time 128.8616s, training loss at epoch 67: 16.1128
using time 123.4609s, training loss at epoch 68: 15.8674
using time 125.4193s, training loss at epoch 69: 15.6640
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   70  | 133.1494767665863 | 385.5816111564636  | 15.497675895690918 | [0.04071145 0.06103163 0.07572871] | [0.01851125 0.02278458 0.02546766] | [0.00228121 0.00172606 0.00143573] | [0.04514221 0.06791048 0.08447917] |
|   70  | 133.1494767665863 | 336.76977729797363 | 15.497675895690918 | [0.05306997 0.0782091  0.09664725] | [0.02344133 0.02875319 0.03211925] | [0.00303715 0.00225915 0.00186773] | [0.05986859 0.08840445 0.10910122] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 117.4154s, training loss at epoch 71: 15.3395
using time 112.5724s, training loss at epoch 72: 15.1638
using time 116.4778s, training loss at epoch 73: 15.0972
using time 129.5095s, training loss at epoch 74: 14.8862
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   75  | 130.13860154151917 | 477.5458793640137 | 14.767184257507324 | [0.04099508 0.06127297 0.07588499] | [0.0186339  0.02289546 0.02556399] | [0.00229618 0.00173172 0.00143768] | [0.045427   0.06812954 0.08461061] |
|   75  | 130.13860154151917 | 328.4217891693115 | 14.767184257507324 | [0.05334427 0.07844328 0.09649296] | [0.02351983 0.0288114  0.03210996] | [0.00305291 0.00226329 0.00186418] | [0.06013646 0.08857778 0.10889638] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 120.3425s, training loss at epoch 76: 14.6207
using time 135.4762s, training loss at epoch 77: 14.4906
using time 127.1884s, training loss at epoch 78: 14.4639
using time 127.6792s, training loss at epoch 79: 14.3033
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   80  | 130.21789479255676 | 503.63313460350037 | 14.214198112487793 | [0.04127596 0.06135472 0.07604163] | [0.01872815 0.02294649 0.02562812] | [0.00230859 0.00173336 0.00144085] | [0.04568988 0.06822447 0.08475665] |
|   80  | 130.21789479255676 | 340.67950677871704 | 14.214198112487793 | [0.05358197 0.07837421 0.09692997] | [0.02351703 0.02874778 0.03213612] | [0.00306355 0.0022625  0.0018718 ] | [0.06038069 0.08855414 0.10938485] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 130.6280s, training loss at epoch 81: 14.1697
using time 130.7095s, training loss at epoch 82: 14.1023
using time 128.9026s, training loss at epoch 83: 13.9704
using time 133.3847s, training loss at epoch 84: 13.9115
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   85  | 131.0864667892456 | 467.65364265441895 | 13.818560600280762 | [0.04121238 0.06140682 0.07624415] | [0.01868817 0.02293393 0.02564208] | [0.00230348 0.00173391 0.00144401] | [0.04558764 0.06821717 0.08496112] |
|   85  | 131.0864667892456 | 390.67946577072144 | 13.818560600280762 | [0.05342465 0.0785076  0.09698492] | [0.02358109 0.02887369 0.03224983] | [0.00305449 0.00226546 0.00187166] | [0.0601916  0.0886408  0.10938485] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 120.3257s, training loss at epoch 86: 13.7829
using time 122.7579s, training loss at epoch 87: 13.6717
using time 137.2731s, training loss at epoch 88: 13.5791
using time 127.8231s, training loss at epoch 89: 13.5906
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   90  | 120.47794032096863 | 443.7257351875305 | 13.480440139770508 | [0.04133442 0.06176785 0.07646008] | [0.01876192 0.02305755 0.0257401 ] | [0.00230896 0.00174377 0.00144815] | [0.04571178 0.06863339 0.08519479] |
|   90  | 120.47794032096863 | 392.5597882270813 | 13.480440139770508 | [0.05346113 0.07863802 0.09707268] | [0.02367113 0.02898238 0.03234693] | [0.00305567 0.00226841 0.00187153] | [0.06019948 0.0887905  0.10943212] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 134.0635s, training loss at epoch 91: 13.4270
using time 128.1707s, training loss at epoch 92: 13.3913
using time 128.1257s, training loss at epoch 93: 13.3500
using time 120.2587s, training loss at epoch 94: 13.2790
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   95  | 114.85991477966309 | 461.1190781593323 | 13.219878196716309 | [0.04165179 0.06207193 0.07666306] | [0.01886485 0.02315276 0.0258143 ] | [0.00232831 0.00175344 0.00145107] | [0.04607689 0.06902771 0.08538464] |
|   95  | 114.85991477966309 | 436.8820903301239 | 13.219878196716309 | [0.05358355 0.0791119  0.09720455] | [0.02371679 0.0290977  0.03240148] | [0.00306158 0.00228082 0.00187324] | [0.06033342 0.08924745 0.1095503 ] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 133.2793s, training loss at epoch 96: 13.1825
using time 128.5309s, training loss at epoch 97: 13.0914
using time 116.2228s, training loss at epoch 98: 13.0883
using time 117.2130s, training loss at epoch 99: 13.0482
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  100  | 116.35579490661621 | 451.42748069763184 | 13.041276931762695 | [0.04171092 0.06217039 0.07680952] | [0.01890175 0.02320161 0.02587476] | [0.00232794 0.00175508 0.00145387] | [0.0460915  0.06910804 0.08555259] |
|  100  | 116.35579490661621 | 475.2870030403137  | 13.041276931762695 | [0.05373249 0.07914908 0.09758325] | [0.02375163 0.02910609 0.03247381] | [0.00306985 0.00228062 0.00188086] | [0.06050674 0.08931835 0.10993634] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 136.3419s, training loss at epoch 101: 12.9686
using time 121.8584s, training loss at epoch 102: 12.9895
using time 120.3475s, training loss at epoch 103: 12.8798
using time 116.3074s, training loss at epoch 104: 12.8462
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  105  | 111.89960098266602 | 462.0495517253876 | 12.846120834350586 | [0.04149212 0.06202462 0.07680728] | [0.01884308 0.02316461 0.02586661] | [0.00231553 0.00174961 0.00145399] | [0.04587243 0.06885976 0.08553069] |
|  105  | 111.89960098266602 | 513.8052067756653 | 12.846120834350586 | [0.05380993 0.07918113 0.09781503] | [0.02376759 0.02911657 0.03252205] | [0.003073   0.00228043 0.00188532] | [0.06057765 0.08933411 0.11023572] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 114.0576s, training loss at epoch 106: 12.7829
using time 125.4993s, training loss at epoch 107: 12.7398
using time 122.1903s, training loss at epoch 108: 12.7078
using time 113.1618s, training loss at epoch 109: 12.6844
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  110  | 113.2828516960144 | 471.3663241863251 | 12.654921531677246 | [0.04212224 0.06237277 0.07723665] | [0.01901842 0.02326997 0.02598742] | [0.00234875 0.00175782 0.00146166] | [0.04653693 0.06920296 0.08598342] |
|  110  | 113.2828516960144 | 527.7058615684509 | 12.654921531677246 | [0.05388808 0.07936795 0.09798373] | [0.0238298  0.02920495 0.03260234] | [0.00307655 0.00228712 0.00188808] | [0.06062492 0.08956259 0.11039329] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 120.0776s, training loss at epoch 111: 12.6609
using time 119.5938s, training loss at epoch 112: 12.5978
using time 107.2658s, training loss at epoch 113: 12.5663
using time 110.1015s, training loss at epoch 114: 12.5225
+-------+--------------------+------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |  tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  115  | 110.43677616119385 | 463.904988527298 | 12.555492401123047 | [0.04213188 0.06246458 0.07727377] | [0.01900608 0.02327507 0.02598025] | [0.00234802 0.00176093 0.00146214] | [0.04651502 0.06929789 0.08601994] |
|  115  | 110.43677616119385 | 508.097501039505 | 12.555492401123047 | [0.05390815 0.07923198 0.09800828] | [0.0238377  0.02918164 0.03261036] | [0.00307734 0.00228299 0.00188808] | [0.06066431 0.08944441 0.11041693] |
+-------+--------------------+------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 115.8643s, training loss at epoch 116: 12.5275
using time 109.7888s, training loss at epoch 117: 12.5344
using time 113.3855s, training loss at epoch 118: 12.4597
using time 113.4081s, training loss at epoch 119: 12.4708
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  120  | 126.54041361808777 | 504.6137418746948 | 12.434487342834473 | [0.04224711 0.06261004 0.07741418] | [0.01907365 0.02335296 0.0260564 ] | [0.00235606 0.00176531 0.00146458] | [0.04666107 0.06948775 0.08613677] |
|  120  | 126.54041361808777 | 458.4318015575409 | 12.434487342834473 | [0.05392484 0.07912402 0.09788671] | [0.02382471 0.02914367 0.03256926] | [0.00307734 0.00227984 0.00188453] | [0.06070371 0.08927896 0.11021997] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 110.3958s, training loss at epoch 121: 12.4020
using time 106.5102s, training loss at epoch 122: 12.3892
using time 104.5472s, training loss at epoch 123: 12.3608
using time 119.0620s, training loss at epoch 124: 12.3503
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  125  | 129.90199637413025 |  514.659862279892 | 12.355644226074219 | [0.04231562 0.06283819 0.07766243] | [0.01913139 0.02344458 0.02615748] | [0.0023619  0.00177078 0.00147066] | [0.0467706  0.06973603 0.08650188] |
|  125  | 129.90199637413025 | 482.9015438556671 | 12.355644226074219 | [0.05402455 0.07948627 0.098017  ] | [0.02383036 0.02919897 0.03258208] | [0.00307773 0.00228712 0.00188611] | [0.06069583 0.08961774 0.11029087] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 110.2749s, training loss at epoch 126: 12.3037
using time 95.0169s, training loss at epoch 127: 12.2817
using time 107.3932s, training loss at epoch 128: 12.2865
using time 127.6056s, training loss at epoch 129: 12.2548
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  130  | 134.58947849273682 | 450.21996426582336 | 12.217033386230469 | [0.04265281 0.06298379 0.07804399] | [0.01924314 0.02352058 0.02627283] | [0.00237869 0.00177681 0.00147845] | [0.04712111 0.06991858 0.0869108 ] |
|  130  | 134.58947849273682 | 452.53628301620483 | 12.217033386230469 | [0.05398763 0.07948889 0.09805891] | [0.02382362 0.0291931  0.03258763] | [0.00307773 0.00228594 0.00188768] | [0.06068795 0.08956259 0.1103539 ] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 117.6413s, training loss at epoch 131: 12.1866
using time 123.7476s, training loss at epoch 132: 12.2291
using time 122.4707s, training loss at epoch 133: 12.1956
using time 126.9477s, training loss at epoch 134: 12.1459
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  135  | 132.17653369903564 |  438.511182308197 | 12.158885955810547 | [0.04259222 0.06297396 0.07783573] | [0.019254   0.02354218 0.02625604] | [0.00237322 0.00177681 0.00147298] | [0.04702618 0.06993318 0.08666253] |
|  135  | 132.17653369903564 | 479.1139826774597 | 12.158885955810547 | [0.05379488 0.0793043  0.09804902] | [0.02381541 0.02919306 0.03262058] | [0.00306827 0.00228003 0.00188677] | [0.06050674 0.08934987 0.11034602] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 123.0432s, training loss at epoch 136: 12.1510
using time 124.9143s, training loss at epoch 137: 12.1460
using time 128.2229s, training loss at epoch 138: 12.1053
using time 127.6213s, training loss at epoch 139: 12.0913
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  140  | 127.75327658653259 | 413.52483201026917 | 12.059992790222168 | [0.04244794 0.06286767 0.07796983] | [0.01915997 0.0234542  0.02621085] | [0.00236518 0.00177133 0.00147395] | [0.04687283 0.06972142 0.08672095] |
|  140  | 127.75327658653259 | 468.24567914009094 | 12.059992790222168 | [0.05396593 0.07954183 0.09840633] | [0.02391846 0.02930912 0.03275311] | [0.00307537 0.00228712 0.00189254] | [0.06065644 0.08961774 0.11070843] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 113.3205s, training loss at epoch 141: 12.0618
using time 132.6415s, training loss at epoch 142: 12.0492
using time 135.0969s, training loss at epoch 143: 12.0479
using time 142.4223s, training loss at epoch 144: 12.0229
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  145  | 132.30495238304138 | 393.32656025886536 | 12.050046920776367 | [0.0427688  0.06302611 0.07822505] | [0.01933177 0.02359467 0.02636995] | [0.00238344 0.00177754 0.00147991] | [0.04723064 0.06994049 0.08707875] |
|  145  | 132.30495238304138 | 522.8904583454132  | 12.050046920776367 | [0.05397566 0.07927542 0.09847187] | [0.02388936 0.02922234 0.03273091] | [0.00307812 0.00227846 0.00189504] | [0.06069583 0.08928684 0.11081873] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 131.8255s, training loss at epoch 146: 12.0099
using time 135.1276s, training loss at epoch 147: 12.0077
using time 134.8504s, training loss at epoch 148: 12.0085
using time 131.3299s, training loss at epoch 149: 11.9589
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  150  | 125.52544331550598 | 343.7041597366333 | 11.972443580627441 | [0.0428779  0.06316964 0.07817641] | [0.01935841 0.02362619 0.02636713] | [0.00239038 0.00178174 0.00147906] | [0.04736208 0.07010844 0.08703494] |
|  150  | 125.52544331550598 | 523.2873284816742 | 11.972443580627441 | [0.05410228 0.07960005 0.09848065] | [0.02388921 0.02926391 0.03270823] | [0.00308443 0.00228811 0.00189267] | [0.06082976 0.08968076 0.11070843] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 131.7726s, training loss at epoch 151: 11.9587
using time 133.6317s, training loss at epoch 152: 11.9233
using time 133.6307s, training loss at epoch 153: 11.9436
using time 130.7809s, training loss at epoch 154: 11.9451
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  155  | 123.90958619117737 | 321.32727909088135 | 11.87517261505127 | [0.04277601 0.06324553 0.07810274] | [0.01933244 0.02363776 0.02635607] | [0.00238307 0.0017832  0.00147809] | [0.04722334 0.07017416 0.08696192] |
|  155  | 123.90958619117737 | 516.6089608669281  | 11.87517261505127 | [0.05431558 0.07959685 0.09857878] | [0.02399651 0.02932037 0.03278581] | [0.00309821 0.00228791 0.00189477] | [0.06108975 0.08964925 0.11084237] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 127.1347s, training loss at epoch 156: 11.9189
using time 134.4669s, training loss at epoch 157: 11.9232
using time 134.3220s, training loss at epoch 158: 11.8456
using time 133.1478s, training loss at epoch 159: 11.8739
+-------+-------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |       Loss      |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  160  | 129.9656195640564 | 321.5194191932678 | 11.882568359375 | [0.04286476 0.06342305 0.07825016] | [0.01937665 0.02369742 0.02641192] | [0.00239111 0.00178776 0.00148186] | [0.04739129 0.07037132 0.08717368] |
|  160  | 129.9656195640564 | 469.5970447063446 | 11.882568359375 | [0.0541214  0.07985603 0.0985961 ] | [0.02390597 0.02933072 0.03275532] | [0.00308482 0.00229461 0.00189609] | [0.06082188 0.089925   0.11089752] |
+-------+-------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 129.3252s, training loss at epoch 161: 11.8652
using time 138.2122s, training loss at epoch 162: 11.8347
using time 134.6017s, training loss at epoch 163: 11.8386
using time 133.7971s, training loss at epoch 164: 11.8649
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  165  | 133.30794835090637 | 358.13840079307556 | 11.855382919311523 | [0.04278551 0.06340457 0.07850888] | [0.01938656 0.02372561 0.02648904] | [0.0023838  0.00178758 0.00148673] | [0.04724524 0.07033481 0.08749498] |
|  165  | 133.30794835090637 | 423.74537920951843 | 11.855382919311523 | [0.05408982 0.07976689 0.0988444 ] | [0.02388806 0.02930057 0.03278891] | [0.00308324 0.00229126 0.00190134] | [0.06076673 0.08978318 0.11120478] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 138.0412s, training loss at epoch 166: 11.8070
using time 136.3987s, training loss at epoch 167: 11.8055
using time 134.2743s, training loss at epoch 168: 11.7862
using time 131.9180s, training loss at epoch 169: 11.7816
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  170  | 132.98218250274658 | 386.43535900115967 | 11.774374961853027 | [0.04286402 0.06342235 0.07858949] | [0.01935797 0.02368023 0.02645229] | [0.00238965 0.00178721 0.00148722] | [0.04736938 0.07035671 0.08750958] |
|  170  | 132.98218250274658 |  391.371639251709  | 11.774374961853027 | [0.05404829 0.07990228 0.09895378] | [0.02393468 0.02938121 0.03286678] | [0.00308403 0.00229441 0.00190528] | [0.060814   0.08994863 0.11137023] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 123.6035s, training loss at epoch 171: 11.7385
using time 141.5290s, training loss at epoch 172: 11.7911
using time 138.0849s, training loss at epoch 173: 11.7893
using time 130.3415s, training loss at epoch 174: 11.7594
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  175  | 126.85332489013672 | 432.7412142753601  | 11.761741638183594 | [0.04294755 0.06376893 0.07866452] | [0.01939987 0.02377913 0.02650139] | [0.0023922  0.00179671 0.00148855] | [0.0474278  0.07071452 0.08758261] |
|  175  | 126.85332489013672 | 372.34201526641846 | 11.761741638183594 | [0.05394596 0.080163   0.09915195] | [0.02391557 0.02943762 0.03290616] | [0.00307734 0.00230209 0.00190725] | [0.06068795 0.09025589 0.11146477] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 131.2874s, training loss at epoch 176: 11.7597
using time 132.8281s, training loss at epoch 177: 11.7491
using time 127.2715s, training loss at epoch 178: 11.7269
using time 133.1312s, training loss at epoch 179: 11.7045
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  180  | 125.4778642654419 | 450.1881878376007  | 11.698224067687988 | [0.04284922 0.06375876 0.07880439] | [0.01940521 0.02380382 0.0265518 ] | [0.00239001 0.00179835 0.0014916 ] | [0.04737668 0.07078754 0.08775786] |
|  180  | 125.4778642654419 | 376.47085523605347 | 11.698224067687988 | [0.05431572 0.07992367 0.09941703] | [0.02407904 0.02947412 0.0330335 ] | [0.00309427 0.00229599 0.00191185] | [0.0610346  0.0899959  0.11178779] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 119.7525s, training loss at epoch 181: 11.7244
using time 135.4426s, training loss at epoch 182: 11.7224
using time 138.6671s, training loss at epoch 183: 11.7037
using time 129.8832s, training loss at epoch 184: 11.6884
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  185  | 117.30803847312927 | 496.67879247665405 | 11.679506301879883 | [0.04280431 0.06380414 0.07879788] | [0.0193646  0.02377869 0.02651689] | [0.00238563 0.00179744 0.00149062] | [0.04728906 0.07070722 0.08773595] |
|  185  | 117.30803847312927 | 379.8925380706787  | 11.679506301879883 | [0.05402242 0.07992325 0.09918983] | [0.02393582 0.02939301 0.0329107 ] | [0.00307852 0.00229658 0.00190738] | [0.06075886 0.09001166 0.11155931] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 111.3111s, training loss at epoch 186: 11.7096
using time 128.8007s, training loss at epoch 187: 11.6730
using time 127.2634s, training loss at epoch 188: 11.6530
using time 114.0528s, training loss at epoch 189: 11.6411
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  190  | 120.65766382217407 | 521.8356475830078  | 11.668601989746094 | [0.04296893 0.06373392 0.07893796] | [0.01940592 0.02377638 0.02655607] | [0.00239257 0.00179561 0.00149415] | [0.0474351  0.0706342  0.08794772] |
|  190  | 120.65766382217407 | 377.14187955856323 | 11.668601989746094 | [0.0540473  0.08004334 0.09915688] | [0.02396795 0.02943789 0.03293205] | [0.0030797  0.00229618 0.00190646] | [0.06079037 0.09000378 0.11155931] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 120.4981s, training loss at epoch 191: 11.6381
using time 124.4645s, training loss at epoch 192: 11.6444
using time 115.0327s, training loss at epoch 193: 11.6498
using time 118.6567s, training loss at epoch 194: 11.6468
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  195  | 104.9467248916626 | 444.57350039482117 | 11.664546966552734 | [0.04299809 0.06377087 0.07891966] | [0.01943977 0.02381097 0.02657889] | [0.00239549 0.00179652 0.00149257] | [0.04747161 0.07067071 0.08783818] |
|  195  | 104.9467248916626 | 295.0661315917969  | 11.664546966552734 | [0.05424485 0.08022026 0.09922499] | [0.02396671 0.02943142 0.03290302] | [0.003086   0.00230052 0.00190764] | [0.06090067 0.09020074 0.11161446] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 127.7901s, training loss at epoch 196: 11.6285
using time 104.8354s, training loss at epoch 197: 11.6794
using time 104.6319s, training loss at epoch 198: 11.6185
using time 107.7136s, training loss at epoch 199: 11.6283
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  200  | 108.44877171516418 | 370.82103848457336 | 11.59388542175293 | [0.04295941 0.06376027 0.07902719] | [0.01943525 0.02381201 0.02659906] | [0.0023933  0.00179671 0.00149464] | [0.04740589 0.07071452 0.08794041] |
|  200  | 108.44877171516418 | 299.04961585998535 | 11.59388542175293 | [0.0544366  0.08020833 0.09942153] | [0.02408433 0.0295074  0.03301172] | [0.00310176 0.00230288 0.00191001] | [0.06117641 0.09024801 0.11180354] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 99.5690s, training loss at epoch 201: 11.6428
using time 107.6999s, training loss at epoch 202: 11.5880
using time 111.4963s, training loss at epoch 203: 11.5999
using time 109.9117s, training loss at epoch 204: 11.5803
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  205  | 107.7413980960846 | 366.1601722240448 | 11.609502792358398 | [0.04302571 0.06368007 0.0790813 ] | [0.01945773 0.02380706 0.02661952] | [0.00239585 0.00179543 0.00149525] | [0.04746431 0.07061229 0.08802804] |
|  205  | 107.7413980960846 | 295.7737009525299 | 11.609502792358398 | [0.05446359 0.08018996 0.09924175] | [0.02408553 0.02949773 0.03297823] | [0.00310333 0.00230091 0.00190738] | [0.06119217 0.09020074 0.11161446] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
early stopping at 205, recall@20:0.0545
(pt170) [01;32mttchungac@dycpu3[00m:[01;34m~/mixgcf/topkmean/MixGCF$[00m exit
exit
kttchungac@dycpu3:MixGCF\[ttchungac@dycpu3 MixGCF]$ exit
exit

Script done on Mon 15 Nov 2021 11:18:25 PM HKT
