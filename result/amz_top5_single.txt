Script started on Mon 15 Nov 2021 02:35:17 AM HKT
kttchungac@dycpu3:MixGCF\[ttchungac@dycpu3 MixGCF]$ c[Kbash
c(base) [01;32mttchungac@dycpu3[00m:[01;34m~/mixgcf/topk/MixGCF$[00m conda activate pt170
(pt170) [01;32mttchungac@dycpu3[00m:[01;34m~/mixgcf/topk/MixGCF$[00m python main.py --dataset yelp2018 --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 3 --gnn lightgcn -- M
^[[D     usage: main.py [-h] [--dataset [DATASET]] [--data_path [DATA_PATH]]
               [--gnn [GNN]] [--epoch EPOCH] [--topk TOPK]
               [--batch_size BATCH_SIZE] [--test_batch_size TEST_BATCH_SIZE]
               [--dim DIM] [--l2 L2] [--lr LR] [--mess_dropout MESS_DROPOUT]
               [--mess_dropout_rate MESS_DROPOUT_RATE]
               [--edge_dropout EDGE_DROPOUT]
               [--edge_dropout_rate EDGE_DROPOUT_RATE]
               [--batch_test_flag BATCH_TEST_FLAG] [--ns NS] [--K K]
               [--n_negs N_NEGS] [--pool POOL] [--cuda CUDA] [--gpu_id GPU_ID]
               [--Ks [KS]] [--test_flag [TEST_FLAG]]
               [--context_hops CONTEXT_HOPS] [--save SAVE] [--out_dir OUT_DIR]
main.py: error: unrecognized arguments: --
(pt170) [01;32mttchungac@dycpu3[00m:[01;34m~/mixgcf/topk/MixGCF$[00m topk 5 --context_hops 3 --pool mean --ns mixgcf --K 1 --n_negs 6[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[Kpython main.py --dataset yelp2018 --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 3 --gnn lightgcn -- M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython main.py --dataset yelp2018 --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 3 --gnn lightgcn -- M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[K
[KM[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython main.py --dataset amazon --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 3 --gnn lightgcn -- t opk 5 --context_hops 3 --pool mean --ns mixgcf --K 1 --n_negs 16
usage: main.py [-h] [--dataset [DATASET]] [--data_path [DATA_PATH]]
               [--gnn [GNN]] [--epoch EPOCH] [--topk TOPK]
               [--batch_size BATCH_SIZE] [--test_batch_size TEST_BATCH_SIZE]
               [--dim DIM] [--l2 L2] [--lr LR] [--mess_dropout MESS_DROPOUT]
               [--mess_dropout_rate MESS_DROPOUT_RATE]
               [--edge_dropout EDGE_DROPOUT]
               [--edge_dropout_rate EDGE_DROPOUT_RATE]
               [--batch_test_flag BATCH_TEST_FLAG] [--ns NS] [--K K]
               [--n_negs N_NEGS] [--pool POOL] [--cuda CUDA] [--gpu_id GPU_ID]
               [--Ks [KS]] [--test_flag [TEST_FLAG]]
               [--context_hops CONTEXT_HOPS] [--save SAVE] [--out_dir OUT_DIR]
main.py: error: unrecognized arguments: -- topk 5 --context_hops 3 --pool mean --ns mixgcf --K 1 --n_negs 16
(pt170) [01;32mttchungac@dycpu3[00m:[01;34m~/mixgcf/topk/MixGCF$[00m python main.py --dataset amazon --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 3 --gnn lightgcn -- toopk 5 --context_hops 3 --pool mean --ns mixgcf --K 1 --n_negs 16M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ctop[1PM(pt170) [01;32mttchungac@dycpu3[00m:[01;34m~/mixgcf/topk/MixGCF$[00m [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C

reading train and test user-item set ...
building the adj mat ...
loading over ...
start training ...
) +-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 93.12385964393616 | 454.0419352054596 | 340.05438232421875 | [0.01357751 0.03676291 0.04507499] | [0.0052742  0.01024031 0.01174632] | [0.00074081 0.00104166 0.00085789] | [0.01476505 0.04137427 0.05097667] |
|   0   | 93.12385964393616 | 576.3899526596069 | 340.05438232421875 | [0.0351756  0.04481311 0.0590424 ] | [0.01622587 0.01822863 0.02081138] | [0.00202871 0.00129266 0.00113096] | [0.04036934 0.05121801 0.06698286] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 108.4519s, training loss at epoch 1: 255.7676
using time 99.2717s, training loss at epoch 2: 244.0094
using time 92.7006s, training loss at epoch 3: 237.8205
using time 93.2870s, training loss at epoch 4: 232.4461
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 94.91884469985962 | 368.90270352363586 | 227.7972412109375 | [0.02229004 0.03639626 0.0468521 ] | [0.00744848 0.01039797 0.01229775] | [0.00125853 0.00103217 0.00089537] | [0.02507576 0.04100916 0.05315273] |
|   5   | 94.91884469985962 | 594.5131871700287  | 227.7972412109375 | [0.03473543 0.04663212 0.06021355] | [0.01614849 0.0186097  0.02107429] | [0.00200389 0.00134368 0.00115394] | [0.03986512 0.05319551 0.06835371] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 120.0602s, training loss at epoch 6: 222.6591
using time 108.8711s, training loss at epoch 7: 217.3192
using time 101.8207s, training loss at epoch 8: 212.0026
using time 95.7803s, training loss at epoch 9: 206.3253
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 83.50585269927979 | 358.66007590293884 | 200.4340057373047 | [0.02629328 0.04235508 0.0541832 ] | [0.00893519 0.01227722 0.01442711] | [0.00150133 0.00121582 0.00104421] | [0.0298514  0.04815802 0.06184235] |
|   10  | 83.50585269927979 | 464.1185083389282  | 200.4340057373047 | [0.03578723 0.04980512 0.06312272] | [0.01644483 0.01936858 0.02180168] | [0.00207598 0.00144984 0.00122445] | [0.04125173 0.05726869 0.07226932] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 105.9080s, training loss at epoch 11: 194.5057
using time 109.1192s, training loss at epoch 12: 188.2294
using time 97.5231s, training loss at epoch 13: 181.9904
using time 93.6781s, training loss at epoch 14: 175.6958
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 97.93167328834534 | 435.0150203704834  | 169.26358032226562 | [0.02801058 0.04712714 0.06016434] | [0.0102816  0.01428782 0.01666194] | [0.00160575 0.0013531  0.00115448] | [0.03191792 0.05343021 0.06820987] |
|   15  | 97.93167328834534 | 360.66746735572815 | 169.26358032226562 | [0.03765977 0.05304325 0.06764265] | [0.01676196 0.0199801  0.02266179] | [0.00219376 0.00155245 0.00132661] | [0.04345771 0.06108187 0.07784728] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 96.0228s, training loss at epoch 16: 163.0873
using time 115.4347s, training loss at epoch 17: 156.8821
using time 102.1181s, training loss at epoch 18: 150.9048
using time 100.2949s, training loss at epoch 19: 144.3715
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 97.18127775192261 | 557.4239134788513 | 137.86073303222656 | [0.02852008 0.04930963 0.06311214] | [0.01127799 0.01564392 0.01816008] | [0.00163168 0.00141206 0.00120718] | [0.03237066 0.05575231 0.07121837] |
|   20  | 97.18127775192261 | 372.1559660434723 | 137.86073303222656 | [0.03946391 0.05517307 0.07002441] | [0.01696507 0.02025734 0.02298788] | [0.00230091 0.00161647 0.00137703] | [0.04546672 0.06347693 0.08061263] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 85.4763s, training loss at epoch 21: 131.4623
using time 89.4673s, training loss at epoch 22: 124.8988
using time 88.7569s, training loss at epoch 23: 118.4241
using time 95.8708s, training loss at epoch 24: 111.9864
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 95.56808829307556 | 588.7483217716217  | 105.80135345458984 | [0.02975134 0.0504227  0.06459861] | [0.01201731 0.01635925 0.01893987] | [0.00169959 0.00144346 0.00123261] | [0.03370696 0.05694257 0.07277374] |
|   25  | 95.56808829307556 | 407.33604645729065 | 105.80135345458984 | [0.04021755 0.05710205 0.07208062] | [0.01714035 0.02067976 0.0234279 ] | [0.00234976 0.00167418 0.00141642] | [0.04639638 0.06569079 0.08291315] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 87.7969s, training loss at epoch 26: 99.4584
using time 83.3878s, training loss at epoch 27: 93.7234
using time 83.8596s, training loss at epoch 28: 87.8218
using time 82.2911s, training loss at epoch 29: 82.2782
+-------+------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 91.0652289390564 | 633.6038825511932 | 77.18682098388672 | [0.03044255 0.05141057 0.06566636] | [0.01246986 0.01686832 0.01946292] | [0.00173865 0.00147158 0.00125269] | [0.03447369 0.05798678 0.07392749] |
|   30  | 91.0652289390564 | 484.8979637622833 | 77.18682098388672 | [0.04116544 0.05823813 0.07361131] | [0.01743656 0.02102942 0.02384727] | [0.00239821 0.00171101 0.00144833] | [0.0473418  0.06706164 0.0847252 ] |
+-------+------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 87.5382s, training loss at epoch 31: 72.1145
using time 90.4051s, training loss at epoch 32: 67.5194
using time 83.9703s, training loss at epoch 33: 62.9164
using time 83.5682s, training loss at epoch 34: 58.9400
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   35  | 83.20997405052185 | 602.8869361877441  | 54.973793029785156 | [0.03128106 0.05192591 0.06601533] | [0.01286157 0.01719077 0.0197542 ] | [0.00178539 0.00148527 0.00125805] | [0.03539377 0.05852715 0.07422688] |
|   35  | 83.20997405052185 | 476.58965492248535 | 54.973793029785156 | [0.04156092 0.05933813 0.07509654] | [0.017599   0.021342   0.02423047] | [0.00242263 0.00174016 0.00147564] | [0.047783   0.06821978 0.08634029] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 88.7168s, training loss at epoch 36: 51.3061
using time 83.7847s, training loss at epoch 37: 48.1704
using time 82.8597s, training loss at epoch 38: 44.9631
using time 84.1942s, training loss at epoch 39: 42.0665
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   40  | 85.52928948402405 | 581.1754620075226 | 39.59113311767578 | [0.0316173  0.05236293 0.06649092] | [0.01312909 0.01748118 0.02005123] | [0.00180401 0.00149659 0.00126669] | [0.03572967 0.05894337 0.07471613] |
|   40  | 85.52928948402405 | 487.6417455673218 | 39.59113311767578 | [0.04196042 0.05994854 0.07590394] | [0.01770785 0.02149866 0.02442306] | [0.00244469 0.0017573  0.00148956] | [0.04820843 0.06888157 0.08717541] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 98.8778s, training loss at epoch 41: 37.1219
using time 90.4951s, training loss at epoch 42: 34.9717
using time 84.4644s, training loss at epoch 43: 33.0677
using time 83.8717s, training loss at epoch 44: 31.2518
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   45  | 86.26613426208496 | 492.1851944923401 | 29.441234588623047 | [0.03212736 0.05263774 0.06691281] | [0.01336279 0.01766722 0.02026133] | [0.00183176 0.00150389 0.00127399] | [0.03626273 0.05923546 0.07516886] |
|   45  | 86.26613426208496 | 465.4899742603302 | 29.441234588623047 | [0.04231661 0.06068329 0.0768054 ] | [0.01782651 0.02169454 0.02465276] | [0.00246557 0.00177561 0.00150584] | [0.04864963 0.06965366 0.08815234] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 102.9870s, training loss at epoch 46: 27.8603
using time 97.6316s, training loss at epoch 47: 26.4987
using time 100.0775s, training loss at epoch 48: 25.3012
using time 85.6175s, training loss at epoch 49: 24.0986
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   50  | 82.69330596923828 | 455.1060540676117 | 22.963390350341797 | [0.03234879 0.05292003 0.06705108] | [0.01347292 0.0177918  0.02036191] | [0.00184089 0.0015101  0.00127606] | [0.03644529 0.05950564 0.07527109] |
|   50  | 82.69330596923828 | 491.0726008415222 | 22.963390350341797 | [0.04266865 0.0612461  0.07745344] | [0.01795144 0.02187122 0.02484551] | [0.00248133 0.00179137 0.00151753] | [0.0489884  0.07025243 0.08887716] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 101.8233s, training loss at epoch 51: 21.9757
using time 106.3090s, training loss at epoch 52: 21.0056
using time 96.9004s, training loss at epoch 53: 20.2582
using time 97.0644s, training loss at epoch 54: 19.5417
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   55  | 88.19577717781067 | 492.4259181022644  | 18.896408081054688 | [0.03257492 0.05281624 0.06744909] | [0.01356113 0.01781376 0.02047682] | [0.00185257 0.00150717 0.00128373] | [0.03667896 0.05942532 0.07573844] |
|   55  | 88.19577717781067 | 462.64491271972656 | 18.896408081054688 | [0.04288756 0.06197465 0.07795722] | [0.01804976 0.02206905 0.02500288] | [0.00249196 0.0018087  0.00152632] | [0.04922476 0.07095361 0.08934199] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 102.8185s, training loss at epoch 56: 18.2170
using time 96.4241s, training loss at epoch 57: 17.6258
using time 98.8309s, training loss at epoch 58: 17.1010
using time 95.9239s, training loss at epoch 59: 16.6530
+-------+------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   60  | 97.4868574142456 | 459.0726568698883  | 16.212318420410156 | [0.0326884  0.05321843 0.06776863] | [0.01362396 0.01793306 0.02057648] | [0.00185878 0.00151813 0.00128896] | [0.0368031  0.05985615 0.07604513] |
|   60  | 97.4868574142456 | 416.19505643844604 | 16.212318420410156 | [0.04322551 0.06243599 0.07833715] | [0.01815275 0.02219817 0.02511448] | [0.00250851 0.0018219  0.00153236] | [0.04954778 0.07150511 0.08978318] |
+-------+------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 98.8135s, training loss at epoch 61: 15.7554
using time 89.9616s, training loss at epoch 62: 15.3690
using time 100.0315s, training loss at epoch 63: 15.0573
using time 94.4012s, training loss at epoch 64: 14.7180
+-------+--------------------+--------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |       Loss      |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   65  | 100.65819358825684 | 470.06505823135376 | 14.382080078125 | [0.0327613  0.05336297 0.0677748 ] | [0.01365868 0.01798153 0.02060185] | [0.0018606  0.00152105 0.00128847] | [0.03684691 0.05996568 0.07602322] |
|   65  | 100.65819358825684 | 414.63408041000366 | 14.382080078125 | [0.04338062 0.06265321 0.07877162] | [0.01823611 0.02229456 0.025251  ] | [0.00251284 0.00182525 0.00153906] | [0.04961868 0.07167843 0.09018499] |
+-------+--------------------+--------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 96.6839s, training loss at epoch 66: 14.1356
using time 96.1166s, training loss at epoch 67: 13.9691
using time 87.2762s, training loss at epoch 68: 13.6406
using time 100.4058s, training loss at epoch 69: 13.3832
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   70  | 99.96396446228027 | 510.68741059303284 | 13.242094993591309 | [0.03279041 0.05345582 0.06794275] | [0.01367615 0.01801299 0.02064845] | [0.00186206 0.00152306 0.001292  ] | [0.03687612 0.06006061 0.07622768] |
|   70  | 99.96396446228027 | 437.6668601036072  | 13.242094993591309 | [0.04367153 0.06308423 0.07909164] | [0.0183336  0.02242127 0.02535288] | [0.00252624 0.00183864 0.00154339] | [0.04990231 0.07220629 0.09053164] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 97.9082s, training loss at epoch 71: 13.0106
using time 93.9679s, training loss at epoch 72: 12.7952
using time 88.1820s, training loss at epoch 73: 12.6879
using time 89.5004s, training loss at epoch 74: 12.5533
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   75  | 98.36891913414001 | 498.52795243263245 | 12.353301048278809 |  [0.0329374 0.0536125 0.0682418]   | [0.0137121  0.01805123 0.02071197] | [0.00186973 0.00152671 0.00129784] | [0.03702946 0.06022856 0.07657089] |
|   75  | 98.36891913414001 | 426.02865743637085 | 12.353301048278809 | [0.04365391 0.06324586 0.07934954] | [0.01831625 0.02244438 0.02539504] | [0.00252505 0.00184199 0.00154707] | [0.04987867 0.0723875  0.09080739] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 99.0206s, training loss at epoch 76: 12.1940
using time 99.2107s, training loss at epoch 77: 12.0617
using time 87.1537s, training loss at epoch 78: 12.0128
using time 85.2471s, training loss at epoch 79: 11.8861
+-------+------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   80  | 88.9201910495758 | 478.6143012046814  | 11.744492530822754 | [0.03297883 0.05364818 0.0681914 ] | [0.01371443 0.01805332 0.02070214] | [0.00186973 0.00152653 0.00129699] | [0.03703677 0.06019935 0.07649056] |
|   80  | 88.9201910495758 | 495.76569080352783 | 11.744492530822754 | [0.04389171 0.06327048 0.07981968] | [0.01839997 0.02248157 0.02550883] | [0.00253805 0.0018414  0.00155337] | [0.05013866 0.07237962 0.09118555] |
+-------+------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 103.7807s, training loss at epoch 81: 11.6575
using time 99.3408s, training loss at epoch 82: 11.6046
using time 91.4371s, training loss at epoch 83: 11.4594
using time 83.3475s, training loss at epoch 84: 11.3500
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   85  | 82.97188544273376 | 423.11597967147827 | 11.333230972290039 | [0.0330768  0.05377878 0.06829317] | [0.01375987 0.01810725 0.0207516 ] | [0.00187374 0.00153018 0.00129833] | [0.03711709 0.0603527  0.07660009] |
|   85  | 82.97188544273376 | 460.98422145843506 | 11.333230972290039 | [0.04378768 0.06354178 0.079951  ] | [0.01841784 0.02257844 0.02557773] | [0.0025286  0.0018479  0.00155429] | [0.04998897 0.07263173 0.0912801 ] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 107.7997s, training loss at epoch 86: 11.2945
using time 110.7810s, training loss at epoch 87: 11.1554
using time 95.8570s, training loss at epoch 88: 11.0563
using time 87.5977s, training loss at epoch 89: 11.0730
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   90  | 85.14213514328003 |  395.385048866272  | 10.953802108764648 | [0.03314198 0.05385838 0.06849378] | [0.01377227 0.01811898 0.0207859 ] | [0.00187703 0.00153109 0.0013021 ] | [0.03719011 0.06042572 0.07683377] |
|   90  | 85.14213514328003 | 475.06189942359924 | 10.953802108764648 | [0.04387259 0.06365485 0.0802166 ] | [0.018473   0.02264008 0.02566964] | [0.00252978 0.00184888 0.0015585 ] | [0.05002048 0.072679   0.09153221] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 107.2613s, training loss at epoch 91: 10.8336
using time 113.3109s, training loss at epoch 92: 10.8418
using time 113.2804s, training loss at epoch 93: 10.7598
using time 102.2901s, training loss at epoch 94: 10.7039
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   95  | 88.77738380432129 | 412.9658372402191  | 10.685750007629395 | [0.03331413 0.05406868 0.0685467 ] | [0.01379587 0.01814598 0.02078814] | [0.00188506 0.00153602 0.00130393] | [0.03735076 0.06063018 0.07697251] |
|   95  | 88.77738380432129 | 466.54947090148926 | 10.685750007629395 | [0.04392194 0.0637692  0.08020904] | [0.01849442 0.0226727  0.0256827 ] | [0.0025282  0.00184869 0.00155718] | [0.05001261 0.07271051 0.09150069] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 100.1813s, training loss at epoch 96: 10.6282
using time 104.1364s, training loss at epoch 97: 10.5839
using time 109.0438s, training loss at epoch 98: 10.5402
using time 98.4655s, training loss at epoch 99: 10.5100
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  100  | 94.86614513397217 | 443.53489661216736 | 10.45199966430664 | [0.03349522 0.05399912 0.06864732] | [0.01382443 0.01812245 0.02080072] | [0.00189529 0.00153273 0.00130624] | [0.03755522 0.06052065 0.07712585] |
|  100  | 94.86614513397217 | 428.07288002967834 | 10.45199966430664 | [0.04389988 0.06366789 0.08047711] | [0.0185013  0.02266463 0.02573908] | [0.0025286  0.00184553 0.00156138] | [0.05003624 0.07260021 0.09178432] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 95.6864s, training loss at epoch 101: 10.4128
using time 98.6684s, training loss at epoch 102: 10.4196
using time 105.5547s, training loss at epoch 103: 10.3414
using time 99.6431s, training loss at epoch 104: 10.3234
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  105  | 96.10151147842407 | 434.77353620529175 | 10.301304817199707 | [0.03341584 0.05403267 0.06860046] | [0.01381012 0.0181318  0.02079299] | [0.00189237 0.00153401 0.0013049 ] | [0.03749681 0.06057906 0.07704553] |
|  105  | 96.10151147842407 | 440.7579936981201  | 10.301304817199707 | [0.04384928 0.06389935 0.08025492] | [0.0184965  0.02272064 0.02571638] | [0.00252466 0.00185144 0.00155823] | [0.04994958 0.07286808 0.09161099] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 95.3588s, training loss at epoch 106: 10.2396
using time 97.4988s, training loss at epoch 107: 10.2312
using time 95.7665s, training loss at epoch 108: 10.1430
using time 97.9935s, training loss at epoch 109: 10.1507
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  110  | 100.82747840881348 | 466.19792008399963 | 10.11585807800293 | [0.03349458 0.05412304 0.06896834] | [0.01379531 0.01812031 0.0208284 ] | [0.00189492 0.00153657 0.00131135] | [0.03755522 0.0606886  0.07746175] |
|  110  | 100.82747840881348 | 480.8819625377655  | 10.11585807800293 | [0.04403404 0.06408603 0.08057261] | [0.01855186 0.02277083 0.02578834] | [0.00253411 0.00185558 0.00156296] | [0.05017018 0.0730808  0.09189462] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 98.1940s, training loss at epoch 111: 10.0955
using time 100.3894s, training loss at epoch 112: 10.0827
using time 98.5730s, training loss at epoch 113: 10.0491
using time 88.5486s, training loss at epoch 114: 10.0067
+-------+------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  115  | 89.9662594795227 | 491.05123567581177 | 10.021648406982422 | [0.03338887 0.05413069 0.06891618] | [0.01375736 0.01810651 0.02080779] | [0.00188981 0.00153602 0.00131148] | [0.03745299 0.06065939 0.07748366] |
|  115  | 89.9662594795227 | 512.4280278682709  | 10.021648406982422 | [0.04385427 0.06417706 0.08058551] | [0.01850522 0.02278255 0.0257866 ] | [0.00252466 0.00185814 0.00156296] | [0.04997321 0.07317534 0.09188674] |
+-------+------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 101.8352s, training loss at epoch 116: 10.0018
using time 101.0742s, training loss at epoch 117: 9.9548
using time 101.6568s, training loss at epoch 118: 9.9152
using time 87.0691s, training loss at epoch 119: 9.9162
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  120  | 88.17256188392639 | 451.8579566478729 | 9.895560264587402 | [0.03355543 0.05429124 0.0690615 ] | [0.01381997 0.01816572 0.02086337] | [0.00189894 0.00154113 0.00131427] | [0.03764285 0.06084925 0.07766622] |
|  120  | 88.17256188392639 | 532.9833567142487 | 9.895560264587402 | [0.04404388 0.06430452 0.08065979] | [0.01855792 0.02281647 0.02580853] | [0.00253608 0.0018609  0.00156322] | [0.05018593 0.07328564 0.09191825] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 108.3707s, training loss at epoch 121: 9.8470
using time 100.1192s, training loss at epoch 122: 9.8337
using time 99.9947s, training loss at epoch 123: 9.7977
using time 85.1550s, training loss at epoch 124: 9.8096
+-------+------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)   |       Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  125  | 85.7491524219513 | 424.73899030685425 | 9.78900146484375 | [0.03369916 0.05438948 0.06927301] | [0.01388176 0.01821508 0.0209335 ] | [0.00190587 0.0015435  0.00131878] | [0.03778159 0.06097338 0.07790719] |
|  125  | 85.7491524219513 | 498.3424768447876  | 9.78900146484375 | [0.04395208 0.06438736 0.08077262] | [0.01852128 0.02281804 0.02581827] | [0.00253254 0.00186306 0.0015665 ] | [0.0501229  0.07336443 0.09209946] |
+-------+------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 107.2488s, training loss at epoch 126: 9.7647
using time 107.5530s, training loss at epoch 127: 9.7345
using time 98.0965s, training loss at epoch 128: 9.7221
using time 91.9963s, training loss at epoch 129: 9.7534
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  130  | 88.09692311286926 | 387.27601861953735 | 9.680498123168945 | [0.03373009 0.05435098 0.06925439] | [0.0138855  0.01820718 0.02093072] | [0.00190734 0.00154296 0.00131902] | [0.03783271 0.06095878 0.07791449] |
|  130  | 88.09692311286926 | 473.7404296398163  | 9.680498123168945 | [0.04394868 0.06447584 0.08085968] | [0.01854459 0.02285554 0.0258579 ] | [0.00253372 0.00186306 0.00156834] | [0.05013078 0.07337231 0.09215461] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 109.7177s, training loss at epoch 131: 9.6665
using time 110.7252s, training loss at epoch 132: 9.6618
using time 116.3414s, training loss at epoch 133: 9.6696
using time 103.9799s, training loss at epoch 134: 9.6481
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  135  | 88.17302131652832 | 360.68545484542847 | 9.654906272888184 | [0.03387419 0.05442711 0.06947969] | [0.01391547 0.01822375 0.02097656] | [0.00191464 0.00154405 0.00132377] | [0.03797875 0.0610172  0.07817007] |
|  135  | 88.17302131652832 | 448.72155499458313 | 9.654906272888184 | [0.04402656 0.06456844 0.0809284 ] | [0.01859158 0.02290443 0.02590236] | [0.00253923 0.00186464 0.001569  ] | [0.05024108 0.07343533 0.09220188] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 97.3548s, training loss at epoch 136: 9.6173
using time 110.0821s, training loss at epoch 137: 9.5967
using time 112.0079s, training loss at epoch 138: 9.5909
using time 109.9532s, training loss at epoch 139: 9.5869
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  140  | 110.46844339370728 | 420.8455402851105 | 9.565526008605957 | [0.03398863 0.05437456 0.06951813] | [0.01396013 0.01823437 0.0210051 ] | [0.00192194 0.00154277 0.00132425] | [0.03811749 0.06095878 0.07823579] |
|  140  | 110.46844339370728 | 368.8773236274719 | 9.565526008605957 | [0.04397228 0.06470736 0.08114037] | [0.01857767 0.02293356 0.02593955] | [0.00253293 0.00186937 0.00157176] | [0.05013866 0.07365593 0.0923752 ] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 98.5300s, training loss at epoch 141: 9.5222
using time 100.8389s, training loss at epoch 142: 9.5532
using time 107.6999s, training loss at epoch 143: 9.5561
using time 111.0535s, training loss at epoch 144: 9.5303
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  145  | 111.27602910995483 | 481.5105721950531 | 9.508341789245605 | [0.03397058 0.0544526  0.06976004] | [0.01397768 0.01827676 0.0210755 ] | [0.00192157 0.00154661 0.00132876] | [0.03811019 0.06111943 0.07852057] |
|  145  | 111.27602910995483 | 378.3673918247223 | 9.508341789245605 | [0.04402483 0.06483437 0.08113596] | [0.01858712 0.02295736 0.02594138] | [0.00253648 0.00187291 0.00157228] | [0.05020169 0.07379774 0.09239096] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 112.3956s, training loss at epoch 146: 9.5022
using time 104.6278s, training loss at epoch 147: 9.5038
using time 123.3809s, training loss at epoch 148: 9.5094
using time 120.5878s, training loss at epoch 149: 9.4875
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  150  | 120.16339707374573 | 479.25346636772156 | 9.474129676818848 | [0.03402713 0.05463519 0.06987039] | [0.01399337 0.01832116 0.02110642] | [0.00192377 0.00155263 0.00133143] | [0.03816131 0.06133849 0.07867392] |
|  150  | 120.16339707374573 | 405.07588624954224 | 9.474129676818848 | [0.04413291 0.06480812 0.08118836] | [0.0186219  0.02296518 0.02596729] | [0.00254081 0.00187094 0.0015736 ] | [0.05028835 0.07371108 0.09250126] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 113.6614s, training loss at epoch 151: 9.4564
using time 103.0707s, training loss at epoch 152: 9.4028
using time 111.8186s, training loss at epoch 153: 9.4305
using time 119.7455s, training loss at epoch 154: 9.4438
+-------+------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  155  | 98.4250693321228 | 509.3536899089813 | 9.406792640686035 | [0.03407123 0.05465204 0.07004932] | [0.01401439 0.01833978 0.02115288] | [0.00192413 0.00155227 0.00133399] | [0.03819051 0.06132389 0.07884917] |
|  155  | 98.4250693321228 | 435.5915033817291 | 9.406792640686035 | [0.04426312 0.06489243 0.08131138] | [0.01868041 0.02301492 0.02601883] | [0.00254672 0.00187449 0.00157504] | [0.05040653 0.07387653 0.09257217] |
+-------+------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 96.8372s, training loss at epoch 156: 9.4535
using time 115.6610s, training loss at epoch 157: 9.3751
using time 106.8298s, training loss at epoch 158: 9.3704
using time 97.3204s, training loss at epoch 159: 9.4154
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |       Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  160  | 113.96919679641724 | 543.9853887557983 | 9.36080551147461 | [0.03408765 0.05467573 0.07000274] | [0.01402647 0.01834992 0.02115107] | [0.00192778 0.00155227 0.00133338] | [0.03824893 0.06132389 0.07880536] |
|  160  | 113.96919679641724 | 464.6443364620209 | 9.36080551147461 | [0.04427051 0.06482368 0.08144472] | [0.01868994 0.02300923 0.02605295] | [0.00254869 0.00187153 0.00157753] | [0.05044592 0.07378199 0.09271398] |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 106.8015s, training loss at epoch 161: 9.3810
using time 103.0678s, training loss at epoch 162: 9.3380
using time 108.3689s, training loss at epoch 163: 9.3622
using time 96.3650s, training loss at epoch 164: 9.3246
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |       Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  165  | 102.08623313903809 | 588.0352427959442 | 9.32674503326416 | [0.03426878 0.05471885 0.07032265] | [0.01409526 0.0183901  0.02123889] | [0.00193727 0.001555   0.00133959] | [0.03843879 0.06142612 0.07916317] |
|  165  | 102.08623313903809 | 471.8221011161804 | 9.32674503326416 | [0.04426584 0.06499327 0.08158411] | [0.01870483 0.02306128 0.02610003] | [0.00254711 0.00187725 0.00158095] | [0.05043017 0.07397895 0.09293458] |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 112.5454s, training loss at epoch 166: 9.3285
using time 98.9443s, training loss at epoch 167: 9.3175
using time 99.1820s, training loss at epoch 168: 9.3006
using time 108.9354s, training loss at epoch 169: 9.3149
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  170  | 101.3905508518219 | 634.6160490512848  | 9.294967651367188 | [0.03415641 0.0547865  0.07017039] | [0.01407233 0.01840436 0.02121524] |  [0.0019307 0.0015561 0.0013363]   | [0.03830735 0.06149914 0.07898791] |
|  170  | 101.3905508518219 | 455.35662603378296 | 9.294967651367188 | [0.04438691 0.06508016 0.08166049] | [0.01871852 0.02306761 0.02610337] | [0.00255342 0.0018802  0.00158187] | [0.05055622 0.07405773 0.09298973] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 94.3695s, training loss at epoch 171: 9.2726
using time 107.4830s, training loss at epoch 172: 9.2915
using time 96.4516s, training loss at epoch 173: 9.2892
using time 106.0043s, training loss at epoch 174: 9.2903
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  175  | 113.5337347984314 | 583.3747653961182  | 9.277600288391113 | [0.03436104 0.05489826 0.07029316] | [0.01413321 0.01844507 0.0212569 ] | [0.00194202 0.00155993 0.00133886] | [0.03852642 0.06162328 0.07913396] |
|  175  | 113.5337347984314 | 468.76831102371216 | 9.277600288391113 | [0.04428077 0.06512281 0.08182337] | [0.01869927 0.02308151 0.02613738] | [0.00254751 0.00188059 0.0015841 ] | [0.05044592 0.07408137 0.09316305] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 94.3482s, training loss at epoch 176: 9.2704
using time 98.6241s, training loss at epoch 177: 9.2526
using time 109.9130s, training loss at epoch 178: 9.2549
using time 100.7673s, training loss at epoch 179: 9.2556
+-------+--------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |       Loss      |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  180  | 114.50495648384094 | 551.6218228340149 | 9.2298002243042 | [0.03434339 0.05486022 0.07029444] | [0.01414933 0.01846007 0.0212782 ] | [0.00194093 0.00155993 0.00133874] | [0.03851911 0.06162328 0.07909745] |
|  180  | 114.50495648384094 | 465.2040545940399 | 9.2298002243042 | [0.04433649 0.06536051 0.08195077] | [0.01872123 0.02313702 0.02617254] | [0.00255145 0.00188709 0.00158594] | [0.05051683 0.07436499 0.09326547] |
+-------+--------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 98.1990s, training loss at epoch 181: 9.2447
using time 106.6508s, training loss at epoch 182: 9.2488
using time 97.2173s, training loss at epoch 183: 9.2316
using time 118.5629s, training loss at epoch 184: 9.2411
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  185  | 116.23467302322388 | 551.1865162849426 | 9.209795951843262 | [0.03442785 0.05504248 0.07032711] | [0.01418229 0.01851294 0.02130343] | [0.00194604 0.00156468 0.00133922] | [0.03859214 0.06182044 0.07912666] |
|  185  | 116.23467302322388 | 462.9232270717621 | 9.209795951843262 | [0.04440577 0.06528514 0.08220279] | [0.01873536 0.0231233  0.02621636] | [0.0025542  0.00188532 0.00159027] | [0.05060349 0.07429409 0.09351758] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 110.0962s, training loss at epoch 186: 9.2538
using time 98.3569s, training loss at epoch 187: 9.1857
using time 104.2381s, training loss at epoch 188: 9.1980
using time 114.2469s, training loss at epoch 189: 9.1915
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  190  | 114.3514838218689 | 544.1513388156891  | 9.209768295288086 | [0.03459253 0.05522998 0.07061921] | [0.0142282  0.01856238 0.02137144] | [0.0019537  0.00156997 0.00134458] | [0.03878199 0.0620176  0.07944065] |
|  190  | 114.3514838218689 | 422.81640362739563 | 9.209768295288086 | [0.0443248  0.06543034 0.08217524] | [0.01873663 0.02316863 0.02623249] | [0.00255145 0.00188887 0.00158988] | [0.05054046 0.07442802 0.09352546] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 107.9404s, training loss at epoch 191: 9.1662
using time 104.9498s, training loss at epoch 192: 9.1888
using time 105.1920s, training loss at epoch 193: 9.1922
using time 122.0447s, training loss at epoch 194: 9.1691
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  195  | 106.85490250587463 | 511.71626806259155 | 9.198843002319336 | [0.03459187 0.0553572  0.07071808] | [0.01423847 0.01859987 0.02139984] | [0.00195553 0.00157472 0.00134555] | [0.0387966  0.06220746 0.07952098] |
|  195  | 106.85490250587463 | 429.7523105144501  | 9.198843002319336 | [0.04439092 0.06543681 0.08242052] | [0.01875961 0.02318302 0.02629043] | [0.0025542  0.00188965 0.00159487] | [0.05059561 0.07445954 0.09380121] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 117.9051s, training loss at epoch 196: 9.1525
using time 106.4115s, training loss at epoch 197: 9.1934
using time 107.4739s, training loss at epoch 198: 9.1559
using time 119.5225s, training loss at epoch 199: 9.1581
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  200  | 107.64342665672302 | 467.3828127384186  | 9.145475387573242 | [0.03461323 0.05549738 0.07073043] | [0.01425986 0.01864493 0.02142162] | [0.00195662 0.00157801 0.0013458 ] | [0.0388039  0.0623389  0.07952828] |
|  200  | 107.64342665672302 | 488.92091274261475 | 9.145475387573242 | [0.04447894 0.06556278 0.08242653] | [0.01876161 0.02319028 0.02627689] | [0.00255854 0.00189202 0.0015946 ] | [0.05068228 0.07455408 0.09378545] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 117.4771s, training loss at epoch 201: 9.1467
using time 108.5007s, training loss at epoch 202: 9.1592
using time 123.9173s, training loss at epoch 203: 9.1383
using time 110.9293s, training loss at epoch 204: 9.1427
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  205  | 103.80304026603699 | 434.97503328323364 | 9.127108573913574 | [0.03477963 0.0555821  0.07064207] | [0.01429012 0.01865588 0.02140041] | [0.00196393 0.00158074 0.00134434] | [0.03895725 0.06244843 0.07946256] |
|  205  | 103.80304026603699 | 422.97544860839844 | 9.127108573913574 | [0.04439976 0.06562518 0.08240691] | [0.01877774 0.02323935 0.02631194] | [0.00255539 0.00189438 0.00159474] | [0.05061137 0.07466438 0.09376182] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
early stopping at 205, recall@20:0.0445
(pt170) [01;32mttchungac@dycpu3[00m:[01;34m~/mixgcf/topk/MixGCF$[00m exit
exit
kttchungac@dycpu3:MixGCF\[ttchungac@dycpu3 MixGCF]$ exit
exit

Script done on Mon 15 Nov 2021 11:18:35 PM HKT
